"""
Converts raw scrobbles table to updated scrobbles table for analysis.
Converts all item_url strings to numeric item IDs
"""
import dbMethods
import datetime
import MySQLdb
import MySQLdb.cursors
import time
import cPickle

### Set up cursors
# streaming cursor, for reading full annotations table from raw database
dbSS = MySQLdb.connect(host="127.0.0.1", user="root", passwd="root",db="crawler_lastfm",cursorclass=MySQLdb.cursors.SSCursor) 
# standard curosr, for writing to new analysis databsase
db = MySQLdb.connect(host="127.0.0.1", user="root", passwd="root",db="analysis_lastfm")

# Drop tables if they exists
cursor=db.cursor()
cursor.execute("DROP TABLE IF EXISTS lastfm_scrobbles;")
# Create new scrobble table
cursor.execute("CREATE TABLE lastfm_scrobbles ( \
	user_id int(10) unsigned NOT NULL, \
	item_id mediumint(8) unsigned NOT NULL, \
	artist_id mediumint(8) unsigned NOT NULL, \
	timestamp timestamp NOT NULL, \
	month date NOT NULL, \
	primary key (user_id,item_id,timestamp), \
	index (item_id), \
	index (user_id), \
	index (month), \
	index (artist_id) \
	) ENGINE=InnoDB DEFAULT CHARSET=latin1;")
db.commit()
cursor.close()

# Load item dictionary generated by prepAnnoTable.py
itemDict = cPickle.load(open('data/itemDict'))

# just for feedback on the script's progress
count = 0 
startTime = time.time()

# open cursors
cursorSS=dbSS.cursor()
cursor=db.cursor()
# Load all scrobbles in streaming cursor
cursorSS.execute("select * from lastfm_scrobbles;")


for row in cursorSS:

	if count > 0:
		if count % 100000 == 0: # Every 100,000 rows, printout progress so far
			minSinceStart = (time.time() - startTime) / 60.0
			print count, minSinceStart, minSinceStart / (count/100000)
			if count % 1000000 == 0: # every million rows, commit new rows to analysis database
				db.commit()

	itemURL = row[1].lower()
	timestamp = row[2]
	month = timestamp.strftime('%Y-%m-01')

	itemID = itemDict.get(itemURL)
	artistName = itemURL.split('/')[0]
	artistID = itemDict.get(artistName)
	
	if not itemID:
		itemID = dbMethods.itemIDfromURL(itemURL,check=False)
		itemDict[itemURL] = itemID
	if not artistID:
		artistID = dbMethods.itemIDfromURL(artistName,check=False)
		itemDict[artistName] = artistID
	cursor.execute("insert ignore into lastfm_scrobbles (user_id,item_id,artist_id,timestamp,month) values (%s,%s,%s,%s,%s)",(row[0],itemID,artistID,timestamp,month))
	count += 1

# Clean everything up, and write updated item dictionary to table
db.commit()
cursor.close()        
cursorSS.close()       
cPickle.dump(itemDict,open('data/itemDict','w'))
